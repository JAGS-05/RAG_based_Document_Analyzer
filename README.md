# RAG Pipeline â€“ Local Document Q&A

A side project buid on the skills I gained during my first internship.  
This is a Retrieval Augmented Generation (RAG) based application that lets you process personal or business documents locally with LLMs ensuring privacy and confidentiality.


## âš™ï¸ Tech Stack
  ğŸ”— LangChain â€“ document loading & chunking  
  ğŸ—ƒï¸ FAISS â€“ vector store  
  ğŸ¦™ Ollama (LLaMA 3.2) â€“ LLM  
  ğŸ§© nomic-embed-text â€“ embeddings  
  ğŸˆ Streamlit â€“ frontend  


## Features
- Local & privacy-preserving  
- Source citations for transparency  
- Works on small-scale documents    


## Example Use Case
Like Twitter/Xâ€™s **â€œSee similar postsâ€** â€” RAG retrieves related chunks and gives grounded answers.


## More Details
ğŸ‘‰ Check out my LinkedIn post here: https://www.linkedin.com/posts/jagathsri-santhanalakshmi-a-53950924a_rag-llm-langchain-activity-7347289178503536640-Oy5o?utm_source=share&utm_medium=member_desktop&rcm=ACoAAD2n270BAuI3Vck6hopMScELuqQCoUTGPPA


## Run Locally
pip install -r requirements.txt
streamlit run app.py
